{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a53ca21-e926-4a10-a955-9a5df6e93542",
   "metadata": {},
   "source": [
    "# Bulk Download GIS Data from National Levee Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2cdcc1-7f98-4963-af88-e503562ba6c8",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to programmatically \"bulk download\" core GIS data from the [National Levee Database](https://levees.sec.usace.army.mil/#/)(NLD) using [GDAL/OGR Python APIs](https://gdal.org/python/). NLD GIS data is available for public access via both ESRI ArcGIS services and OGC services. In this notebook, we focus on retrieving data from the ArcGIS [Feature Service](https://developers.arcgis.com/rest/services-reference/enterprise/feature-service.htm) REST APIs. \n",
    "\n",
    "The offical \"User Guide - NLD Web-GIS services (pdf)\" (shown in the snapshot below) provides instructions on data access using ArcMap, ArcGIS Pro and QGIS. In addition, [ArcGIS Online Map Viewer](https://www.arcgis.com/home/webmap/viewer.html) is also a good tool for quick visualization. \n",
    "\n",
    "<img src=\"statics/images/NLD_gis.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec013d9f-fb8f-4014-b91e-ca20ac4a6333",
   "metadata": {},
   "source": [
    "## Available Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b5d24-1ef7-4219-b8a9-8a7a6403efe0",
   "metadata": {},
   "source": [
    "Here we import some libs we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e63c6b-6349-4ab6-8a68-cc287631a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from werkzeug.utils import secure_filename\n",
    "from osgeo import ogr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d9dc7-1fc2-4554-aa8c-0b6a346b2e62",
   "metadata": {},
   "source": [
    "As the NLD FeatureService endpoint shown in the snapshot above, we here append \"/?f=pjson\" to the url to retrieve metadata for all layers served under the \"NLD2_PUBLIC\" group. We use \"requests\" to make a HTTP GET request to the endpoint and extract the \"layers\" key from the returned JSON data. We put the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966bb20-8e46-44a4-804c-bdb9938427e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_feature_server = \"https://ags03.sec.usace.army.mil/server/rest/services/NLD2_PUBLIC/FeatureServer/\"\n",
    "layer_def = requests.get(url_feature_server + '/?f=pjson').json()\n",
    "\n",
    "df = pd.DataFrame(layer_def[\"layers\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f355e1-7860-4d39-9240-7b2f3a109b78",
   "metadata": {},
   "source": [
    "## Bulk Download all Features from a Single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df394e6-3940-4d10-a316-af2827dede90",
   "metadata": {},
   "source": [
    "Here we write up a reusable function that downloads a single layer data. Later we will appy the this function to all layers. The library we use for interacting with the ArcGIS FeatureService is [GDAL/OGR Python APIs](https://gdal.org/python/). Since a Feature Service layer could contain a lot of features, the total number may be far beyond how many features a single REST API call could return. It is necessary to split a \"big call\" into multiple \"smaller calls\" to retrieve data in chunks and piece them up in the end. There are different ways to do it. The tip of using GDAL/OGR is we should explicitly add a \"resultRecordCount=XXXXX\" to activate the pagination. To determine the best value for \"resultRecordCount\" some \"trial-and-errors\" might be needed. we found 1,000 works well in this case. Note that even the ArcGIS server has a relative large cap, it is still recommended to explicitly set a smaller 'resultRecordCount\" as a 'big call' may cause unexpected errors, such as time-out or wrong query result in some extreme cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb9a9a-5b22-4736-8fdf-fd072a613f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a local folder where the downloaded data will be saved\n",
    "download_folder = os.path.abspath(\"./download\")\n",
    "!mkdir -p {download_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788b4d7-2a81-4f2e-a6fc-7e705ecb8941",
   "metadata": {},
   "source": [
    "Below is the function that downloads a single FeatureLayer to local shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9f756-4399-4b68-9fe6-49e3198c264a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featurelayer2shapefile_ogr(featurelayer_url, shapefile_path):\n",
    "    \"\"\"\n",
    "    Save all data of a ArcGIS FeatureService layer to a local Shapefiles.\n",
    "    This function uses GDAL/OGR Python APIs (https://gdal.org/python/)\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    featurelayer_url: string\n",
    "         The REST endpioint to a specific ArcGIS FeatureService layer. \n",
    "         eg: https://ags03.sec.usace.army.mil/server/rest/services/NLD2_PUBLIC/FeatureServer/0/\n",
    "    shapefile_path: string\n",
    "         The full path of shapefiles to be created locally.\n",
    "         The file extension is expected to be \"*.shp\".\n",
    "         Existing shapefiles will be overwritten.\n",
    "         eg: ~/work/download/myshp.shp\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    No returns\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Here we construct a Query against the FeatureService layer to return all features\n",
    "    # where=1+%3D+1: (decoded: 1 = 1) a always true where clause that will hit on every feature\n",
    "    # outfields=*: reture all attributes\n",
    "    # f=geojson: return results in GeoJSON format\n",
    "    # resultRecordCount=1000: only return 1,000 features per query and make multiple queries if needed\n",
    "    # orderByFields=OBJECTID+ASC: sort results by OBJECTID\n",
    "    # the above query can also be performed using the ogr2ogr command\n",
    "    # ogr2ogr -overwrite -f 'ESRI Shapefile' <Shapefile> <ArcServerFeatureServer>/<LayerID>/query/?where=1+%3D+1&outfields=*&f=geojson&resultRecordCount=1000&orderByFields=OBJECTID+ASC\n",
    "    query_url = '{}/query/?where=1+%3D+1&outfields=*&f=json&resultRecordCount=1000&orderByFields=OBJECTID+ASC'.format(featurelayer_url)\n",
    "    print(query_url)\n",
    "    ds = ogr.Open(query_url)\n",
    "    layer = ds.GetLayerByIndex(0)\n",
    "    # total number of features retrieved from the rest endpoint\n",
    "    feature_count = layer.GetFeatureCount()\n",
    "    print(\"Input Feature Count: {:,}\".format(feature_count))\n",
    "    # create a local shapefile\n",
    "    driver_out = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    # remove output shapefile if it already exists\n",
    "    if os.path.exists(shapefile_path):\n",
    "        driver_out.DeleteDataSource(shapefile_path)\n",
    "    ds_out = driver_out.CreateDataSource(shapefile_path)\n",
    "    # copy GeoJSON layer to local Shapefile files\n",
    "    layer_out = ds_out.CopyLayer(layer, \"layer\")\n",
    "    print(\"Output Feature Count: {:,} at {}\".format(layer_out.GetFeatureCount(), shapefile_path))\n",
    "    # save everything\n",
    "    ds = None\n",
    "    ds_out = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3eb64-e116-457d-b205-a43766de5859",
   "metadata": {},
   "source": [
    "## Bulk Download All NLD Layers (~40 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cad17-c21c-40ff-b34c-237b699b02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of layers to download (by ids)\n",
    "id_list = [4]\n",
    "# uncomment the codes below to download all layers\n",
    "#id_list = range(0, df.shape[0])\n",
    "\n",
    "def row_func(row):\n",
    "    \"\"\"\n",
    "    This function will be applied to each row of the above dataframe \n",
    "    For each row (layer), it calls function featurelayer2shapefile_ogr()\n",
    "    to download the layer data to local shapefiles\n",
    "   \n",
    "    Parameters\n",
    "    ---------\n",
    "    row: pandas.Series\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    No returns\n",
    "    \n",
    "    \"\"\"\n",
    "    name = row[\"name\"]    \n",
    "    id = row[\"id\"]\n",
    "    if id_list is not None and type(id_list) is list:\n",
    "        if int(id) not in id_list:\n",
    "            return\n",
    "    name_safe = secure_filename(name)\n",
    "    shp_path = os.path.join(download_folder, '{}.shp'.format(name_safe))\n",
    "    print(\"-\"*80)\n",
    "    print(\"id: {}; name: {}; file: {}\".format(id, name, shp_path))\n",
    "    featurelayer_url = \"{}/{}/\".format(url_feature_server, id)\n",
    "    featurelayer2shapefile_ogr(featurelayer_url, shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abce35-975b-447a-9930-394036185f72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# bulk download the whole NLD normally takes 30~40 mins\n",
    "_ = df.apply(row_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195144c-a34f-40b5-8c21-b90cc48c05f9",
   "metadata": {},
   "source": [
    "## Quick Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f7605-01de-4771-ac43-e34040819acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du {download_folder} -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511cd4e-eb13-4c05-ac96-6e9175eaed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {download_folder} -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8966d0e-09f0-4ba7-b55a-bebdb5292263",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://gis.stackexchange.com/questions/13029/converting-arcgis-server-json-to-geojson\n",
    "\n",
    "https://gis.stackexchange.com/questions/266897/how-to-get-around-the-1000-objectids-limit-on-arcgis-server\n",
    "\n",
    "https://pcjericks.github.io/py-gdalogr-cookbook/vector_layers.html#get-wfs-layers-and-iterate-over-features\n",
    "\n",
    "https://gdal.org/python/\n",
    "\n",
    "https://gdal.org/drivers/vector/geojson.html#vector-geojson\n",
    "\n",
    "https://gdal.org/drivers/vector/esrijson.html#vector-esrijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240af89-d257-4ae5-ba2d-a1962846f83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-latest-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
